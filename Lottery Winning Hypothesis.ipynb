{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "IoznojN2AHdF",
        "outputId": "a236674a-7046-43ac-f0c4-412c9768826f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 16.3MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 494kB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.33MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 2.89MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "train_data = datasets.MNIST(root='data',train=True,download=True,transform=ToTensor())\n",
        "test_data = datasets.MNIST(root='data',train=False,download=True,transform=ToTensor())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PinVdfmAjTi",
        "outputId": "542e919e-ec5f-4ee1-81fe-916e8b6e3887"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'train': <torch.utils.data.dataloader.DataLoader at 0x79f8df625bd0>,\n",
              " 'test': <torch.utils.data.dataloader.DataLoader at 0x79f8df625720>}"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch.utils.data  import DataLoader\n",
        "import torch\n",
        "\n",
        "\n",
        "loaders={\n",
        "    'train' : torch.utils.data.DataLoader(train_data,batch_size=128,shuffle=True),\n",
        "    'test'  : torch.utils.data.DataLoader(test_data,batch_size=4096)\n",
        "}\n",
        "loaders\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlRG9Pk9BF3a"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Model(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Linear(28*28,1024),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Linear(1024,512),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Linear(512,256),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Linear(256,10)\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = torch.flatten(x,1)\n",
        "    x = self.classifier(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yxtn4UcaBwdX"
      },
      "outputs": [],
      "source": [
        "import torch.nn.init as init\n",
        "\n",
        "def init_weights(module):\n",
        "\n",
        "  if isinstance(module,nn.Linear):\n",
        "    init.xavier_normal_(module.weight.data)\n",
        "    init.normal_(module.bias.data)\n",
        "  else:\n",
        "    ValueError\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_658j3QtDIJQ"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "model = Model()\n",
        "model.apply(init_weights)\n",
        "initial_dict = copy.deepcopy(model.state_dict())\n",
        "optimizer = torch.optim.AdamW(model.parameters(),lr=0.001)\n",
        "loss_func = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Dp_0TWHDyQV",
        "outputId": "412b6d03-4312-4b4e-d03c-0ad3045921ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[None, None, None, None]\n"
          ]
        }
      ],
      "source": [
        "def mask_maker(model):\n",
        "\n",
        "  mask = [None] * sum(1 for name,param in model.named_parameters() if \"weight\" in name)\n",
        "  print(mask)\n",
        "  layer=0\n",
        "  for name,param in model.named_parameters():\n",
        "    if \"weight\" in name:\n",
        "      tensor = param.data\n",
        "      mask[layer] = torch.ones_like(tensor)\n",
        "      layer+=1\n",
        "  return mask\n",
        "\n",
        "mask = mask_maker(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-eRZlbb3EYzh"
      },
      "outputs": [],
      "source": [
        "def prune_percentile(percent,mask):\n",
        "  layer = 0\n",
        "  for name,param in model.named_parameters():\n",
        "    if 'weight' in name:\n",
        "      tensor = param.data\n",
        "      torch_nonzero = torch.nonzero(tensor,as_tuple=True)\n",
        "      alive = tensor[torch_nonzero]\n",
        "      percentile_value = torch.quantile(abs(alive), percent).item()\n",
        "      new_mask = torch.from_numpy(np.where(abs(tensor) < percentile_value, 0, mask[layer]))\n",
        "      mask[layer] = new_mask\n",
        "      layer += 1\n",
        "  return mask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UWBrez4FTDz",
        "outputId": "ab40d7a0-526b-4d7e-aa56-7e934f59e2f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Nodes: tensor(1460736)\n"
          ]
        }
      ],
      "source": [
        "def total_nodes(model):\n",
        "  total = 0\n",
        "  for name,param in model.named_parameters():\n",
        "    if \"weight\" in name:\n",
        "      total += torch.count_nonzero(param.data)\n",
        "  return total\n",
        "\n",
        "original_nodes = total_nodes(model)\n",
        "print(\"Total Nodes:\",original_nodes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcINXqx4F2nt"
      },
      "outputs": [],
      "source": [
        "def reset_to_original_init(model,mask,inital_dict):\n",
        "  layer = 0\n",
        "  for name,param in model.named_parameters():\n",
        "    if \"weight\" in name:\n",
        "      param.data = initial_dict[name] * mask[layer]\n",
        "      layer += 1\n",
        "    if \"bias\" in name:\n",
        "      param.data = initial_dict[name]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHmn1e-nHR2p"
      },
      "outputs": [],
      "source": [
        "def reset_mask(mask):\n",
        "  for step in range(len(mask)):\n",
        "    new_mask = torch.ones_like(mask[step])\n",
        "    mask[step] = new_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "od7c2D07G1v_"
      },
      "outputs": [],
      "source": [
        "def full_reset(model,mask,initial_dict):\n",
        "  reset_mask(mask)\n",
        "  reset_to_original_init(model,mask,initial_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6laRtkRHJMa"
      },
      "outputs": [],
      "source": [
        "full_reset(model,mask,initial_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTuBO-XoHNdC"
      },
      "outputs": [],
      "source": [
        "from torch.autograd import Variable\n",
        "\n",
        "def train_prune(model,loaders,loss_func):\n",
        "\n",
        "   EPS = 1e-6\n",
        "   size = len(loaders['train'].dataset)\n",
        "   for batch_dix,(imgs,targets) in enumerate(loaders['train']):\n",
        "    optimizer.zero_grad()\n",
        "    pred = model(imgs)\n",
        "    train_loss = loss_func(pred,targets)\n",
        "    train_loss.backward()\n",
        "\n",
        "    for name,param in model.named_parameters():\n",
        "      if \"weight\" in name:\n",
        "        tensor = param.data\n",
        "        grad_tensor = param.grad.data\n",
        "        grad_tensor = torch.where(tensor<EPS,0,grad_tensor)\n",
        "        param.grad.data = grad_tensor\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch_dix % 100 == 0:\n",
        "      loss,current = train_loss.item(),batch_dix*len(imgs)\n",
        "      print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13A4AWo8AEZf"
      },
      "outputs": [],
      "source": [
        "def test(model,loaders,loss_func):\n",
        "  test_dataloader = loaders['test']\n",
        "  size = len(test_dataloader.dataset)\n",
        "  num_batches = len(test_dataloader)\n",
        "  test_loss,correct = 0,0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for imgs,targets in test_dataloader:\n",
        "      pred = model(imgs)\n",
        "      test_loss += loss_func(pred,targets).item()\n",
        "      correct += (pred.argmax(1) == targets).type(torch.float).sum().item()\n",
        "  test_loss /= num_batches\n",
        "\n",
        "  correct /= size\n",
        "  print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ay38fwQAbVe",
        "outputId": "962d7f01-3aa1-4ed9-e139-5e883679783c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Error: \n",
            " Accuracy: 9.7%, Avg loss: 3.574221 \n",
            "\n",
            "Number of nodes:1460736\n"
          ]
        }
      ],
      "source": [
        "test(model,loaders,loss_func)\n",
        "nodes = total_nodes(model)\n",
        "print(f\"Number of nodes:{nodes}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mj5hkDqKApRj",
        "outputId": "2da3e78b-672a-4929-afef-723b75d7f816"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "Iteration 1\n",
            "-------------------------------\n",
            "loss: 0.001891 [    0/60000]\n",
            "loss: 0.004102 [12800/60000]\n",
            "loss: 0.002325 [25600/60000]\n",
            "loss: 0.000788 [38400/60000]\n",
            "loss: 0.002691 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.2%, Avg loss: 0.063005 \n",
            "\n",
            "\n",
            "--- Pruning Level [1/20]: ---\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "Iteration 1\n",
            "-------------------------------\n",
            "loss: 2.280112 [    0/60000]\n",
            "loss: 0.226206 [12800/60000]\n",
            "loss: 0.291351 [25600/60000]\n",
            "loss: 0.294636 [38400/60000]\n",
            "loss: 0.365459 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.8%, Avg loss: 0.162615 \n",
            "\n",
            "\n",
            "--- Pruning Level [2/20]: ---\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "Iteration 1\n",
            "-------------------------------\n",
            "loss: 2.223068 [    0/60000]\n",
            "loss: 0.319968 [12800/60000]\n",
            "loss: 0.244551 [25600/60000]\n",
            "loss: 0.230020 [38400/60000]\n",
            "loss: 0.166420 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 95.2%, Avg loss: 0.154853 \n",
            "\n",
            "\n",
            "--- Pruning Level [3/20]: ---\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "Iteration 1\n",
            "-------------------------------\n",
            "loss: 2.217064 [    0/60000]\n",
            "loss: 0.369239 [12800/60000]\n",
            "loss: 0.313892 [25600/60000]\n",
            "loss: 0.186368 [38400/60000]\n",
            "loss: 0.218247 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 94.8%, Avg loss: 0.167094 \n",
            "\n",
            "\n",
            "--- Pruning Level [4/20]: ---\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "Iteration 1\n",
            "-------------------------------\n",
            "loss: 2.050553 [    0/60000]\n",
            "loss: 0.309441 [12800/60000]\n",
            "loss: 0.309148 [25600/60000]\n",
            "loss: 0.276444 [38400/60000]\n",
            "loss: 0.171552 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 93.7%, Avg loss: 0.201066 \n",
            "\n",
            "\n",
            "--- Pruning Level [5/20]: ---\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "Iteration 1\n",
            "-------------------------------\n",
            "loss: 2.154284 [    0/60000]\n",
            "loss: 0.355030 [12800/60000]\n",
            "loss: 0.308141 [25600/60000]\n",
            "loss: 0.467917 [38400/60000]\n",
            "loss: 0.234870 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 92.5%, Avg loss: 0.236245 \n",
            "\n",
            "\n",
            "--- Pruning Level [6/20]: ---\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "Iteration 1\n",
            "-------------------------------\n",
            "loss: 2.387293 [    0/60000]\n",
            "loss: 0.610829 [12800/60000]\n",
            "loss: 0.403033 [25600/60000]\n",
            "loss: 0.312307 [38400/60000]\n",
            "loss: 0.266787 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.9%, Avg loss: 0.261078 \n",
            "\n",
            "\n",
            "--- Pruning Level [7/20]: ---\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "Iteration 1\n",
            "-------------------------------\n",
            "loss: 2.497810 [    0/60000]\n",
            "loss: 0.900582 [12800/60000]\n",
            "loss: 0.443669 [25600/60000]\n",
            "loss: 0.204259 [38400/60000]\n",
            "loss: 0.381262 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 91.2%, Avg loss: 0.290691 \n",
            "\n",
            "\n",
            "--- Pruning Level [8/20]: ---\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "Iteration 1\n",
            "-------------------------------\n",
            "loss: 2.368562 [    0/60000]\n",
            "loss: 1.341000 [12800/60000]\n",
            "loss: 0.583513 [25600/60000]\n",
            "loss: 0.387205 [38400/60000]\n",
            "loss: 0.435930 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.1%, Avg loss: 0.318770 \n",
            "\n",
            "\n",
            "--- Pruning Level [9/20]: ---\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "Iteration 1\n",
            "-------------------------------\n",
            "loss: 2.469908 [    0/60000]\n",
            "loss: 1.679525 [12800/60000]\n",
            "loss: 0.671542 [25600/60000]\n",
            "loss: 0.453534 [38400/60000]\n",
            "loss: 0.295601 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.0%, Avg loss: 0.335603 \n",
            "\n",
            "\n",
            "--- Pruning Level [10/20]: ---\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "Iteration 1\n",
            "-------------------------------\n",
            "loss: 2.717806 [    0/60000]\n",
            "loss: 1.946380 [12800/60000]\n",
            "loss: 1.069265 [25600/60000]\n",
            "loss: 0.549929 [38400/60000]\n",
            "loss: 0.412747 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.3%, Avg loss: 0.365403 \n",
            "\n",
            "\n",
            "--- Pruning Level [11/20]: ---\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "Iteration 1\n",
            "-------------------------------\n",
            "loss: 2.499441 [    0/60000]\n",
            "loss: 2.002674 [12800/60000]\n",
            "loss: 1.530078 [25600/60000]\n",
            "loss: 0.719130 [38400/60000]\n",
            "loss: 0.435719 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.4%, Avg loss: 0.395142 \n",
            "\n",
            "\n",
            "--- Pruning Level [12/20]: ---\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "Iteration 1\n",
            "-------------------------------\n",
            "loss: 2.650818 [    0/60000]\n",
            "loss: 2.120894 [12800/60000]\n",
            "loss: 1.778521 [25600/60000]\n",
            "loss: 1.021955 [38400/60000]\n",
            "loss: 0.553300 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 85.1%, Avg loss: 0.471288 \n",
            "\n",
            "\n",
            "--- Pruning Level [13/20]: ---\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "Iteration 1\n",
            "-------------------------------\n",
            "loss: 2.449502 [    0/60000]\n",
            "loss: 2.151326 [12800/60000]\n",
            "loss: 1.787603 [25600/60000]\n",
            "loss: 1.220395 [38400/60000]\n",
            "loss: 0.665148 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.9%, Avg loss: 0.499296 \n",
            "\n",
            "\n",
            "--- Pruning Level [14/20]: ---\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "Iteration 1\n",
            "-------------------------------\n",
            "loss: 2.454323 [    0/60000]\n",
            "loss: 2.201957 [12800/60000]\n",
            "loss: 1.898190 [25600/60000]\n",
            "loss: 1.459641 [38400/60000]\n",
            "loss: 0.999129 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.6%, Avg loss: 0.583933 \n",
            "\n",
            "\n",
            "--- Pruning Level [15/20]: ---\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "Iteration 1\n",
            "-------------------------------\n",
            "loss: 2.490064 [    0/60000]\n",
            "loss: 2.286591 [12800/60000]\n",
            "loss: 1.941094 [25600/60000]\n",
            "loss: 1.632520 [38400/60000]\n",
            "loss: 1.094606 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 81.1%, Avg loss: 0.764206 \n",
            "\n",
            "\n",
            "--- Pruning Level [16/20]: ---\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "Iteration 1\n",
            "-------------------------------\n",
            "loss: 2.527755 [    0/60000]\n",
            "loss: 2.314658 [12800/60000]\n",
            "loss: 2.111640 [25600/60000]\n",
            "loss: 1.753703 [38400/60000]\n",
            "loss: 1.241790 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 69.0%, Avg loss: 1.006987 \n",
            "\n",
            "\n",
            "--- Pruning Level [17/20]: ---\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "Iteration 1\n",
            "-------------------------------\n",
            "loss: 2.434133 [    0/60000]\n",
            "loss: 2.396594 [12800/60000]\n",
            "loss: 2.233121 [25600/60000]\n",
            "loss: 1.968012 [38400/60000]\n",
            "loss: 1.644655 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 63.5%, Avg loss: 1.270242 \n",
            "\n",
            "\n",
            "--- Pruning Level [18/20]: ---\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "Iteration 1\n",
            "-------------------------------\n",
            "loss: 2.379255 [    0/60000]\n",
            "loss: 2.262722 [12800/60000]\n",
            "loss: 2.285184 [25600/60000]\n",
            "loss: 2.157981 [38400/60000]\n",
            "loss: 1.555933 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 63.0%, Avg loss: 1.279050 \n",
            "\n",
            "\n",
            "--- Pruning Level [19/20]: ---\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "Iteration 1\n",
            "-------------------------------\n",
            "loss: 2.371665 [    0/60000]\n",
            "loss: 2.304135 [12800/60000]\n",
            "loss: 2.267208 [25600/60000]\n",
            "loss: 2.195089 [38400/60000]\n",
            "loss: 1.786638 [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 62.7%, Avg loss: 1.350486 \n",
            "\n",
            "\n",
            "--- Pruning Level [20/20]: ---\n"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "prune_percent = 0.5\n",
        "iterations = 1\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def iterative_prune_train(model,mask,loss_func,iterations,percent):\n",
        "  for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
        "    model.train()\n",
        "    for t in range(iterations):\n",
        "      print(f\"Iteration {t+1}\\n-------------------------------\")\n",
        "      train_prune(model,loaders,loss_func)\n",
        "      test(model,loaders,loss_func)\n",
        "    mask = prune_percentile(percent,mask)\n",
        "    reset_to_original_init(model,mask,initial_dict)\n",
        "    print(f\"\\n--- Pruning Level [{epoch+1}/{epochs}]: ---\")\n",
        "\n",
        "iterative_prune_train(model, mask, loss_func, iterations, prune_percent)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8mwYzBxBoTH",
        "outputId": "0cd8c1da-546c-4ed3-8680-ce132ba2e936"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Error: \n",
            " Accuracy: 11.3%, Avg loss: 2.345188 \n",
            "\n",
            "Number of nodes: 2989\n",
            "Percent of nodes left: 0.002\n"
          ]
        }
      ],
      "source": [
        "# loss_func = nn.CrossEntropyLoss()\n",
        "# full_reset(model, mask, initial_dict)\n",
        "test(model, loaders, loss_func)\n",
        "nodes = total_nodes(model)\n",
        "# print(f\"Accuracy: {acc:.3f}\")\n",
        "print(f\"Number of nodes: {nodes}\")\n",
        "print(f\"Percent of nodes left: {(nodes / original_nodes):.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gdcCpPr4CQ58"
      },
      "outputs": [],
      "source": [
        "full_reset(model, mask, initial_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GI-F2qEyCSDT"
      },
      "outputs": [],
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Compute prediction and loss\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQ-DXdMFCUA2",
        "outputId": "9e68a235-e399-46dc-fde8-7b3df9192a72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.924125  [    0/60000]\n",
            "loss: 0.212223  [12800/60000]\n",
            "loss: 0.284626  [25600/60000]\n",
            "loss: 0.047097  [38400/60000]\n",
            "loss: 0.114272  [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 96.6%, Avg loss: 0.098209 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.086463  [    0/60000]\n",
            "loss: 0.063238  [12800/60000]\n",
            "loss: 0.144997  [25600/60000]\n",
            "loss: 0.062582  [38400/60000]\n",
            "loss: 0.057242  [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.5%, Avg loss: 0.076414 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.013616  [    0/60000]\n",
            "loss: 0.035442  [12800/60000]\n",
            "loss: 0.030279  [25600/60000]\n",
            "loss: 0.011119  [38400/60000]\n",
            "loss: 0.035215  [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.6%, Avg loss: 0.075114 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.030664  [    0/60000]\n",
            "loss: 0.010130  [12800/60000]\n",
            "loss: 0.023699  [25600/60000]\n",
            "loss: 0.015874  [38400/60000]\n",
            "loss: 0.101203  [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.8%, Avg loss: 0.068019 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.008453  [    0/60000]\n",
            "loss: 0.035682  [12800/60000]\n",
            "loss: 0.010226  [25600/60000]\n",
            "loss: 0.005008  [38400/60000]\n",
            "loss: 0.020468  [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.9%, Avg loss: 0.076814 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.010747  [    0/60000]\n",
            "loss: 0.005646  [12800/60000]\n",
            "loss: 0.010466  [25600/60000]\n",
            "loss: 0.002613  [38400/60000]\n",
            "loss: 0.026180  [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.8%, Avg loss: 0.080382 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.006391  [    0/60000]\n",
            "loss: 0.001683  [12800/60000]\n",
            "loss: 0.001235  [25600/60000]\n",
            "loss: 0.007556  [38400/60000]\n",
            "loss: 0.020904  [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.9%, Avg loss: 0.076124 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.001631  [    0/60000]\n",
            "loss: 0.005811  [12800/60000]\n",
            "loss: 0.002624  [25600/60000]\n",
            "loss: 0.006625  [38400/60000]\n",
            "loss: 0.007658  [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.7%, Avg loss: 0.090804 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.003775  [    0/60000]\n",
            "loss: 0.003218  [12800/60000]\n",
            "loss: 0.006858  [25600/60000]\n",
            "loss: 0.014538  [38400/60000]\n",
            "loss: 0.003468  [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.9%, Avg loss: 0.085231 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.014931  [    0/60000]\n",
            "loss: 0.011199  [12800/60000]\n",
            "loss: 0.042001  [25600/60000]\n",
            "loss: 0.007248  [38400/60000]\n",
            "loss: 0.003026  [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.1%, Avg loss: 0.084398 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.015719  [    0/60000]\n",
            "loss: 0.019453  [12800/60000]\n",
            "loss: 0.026093  [25600/60000]\n",
            "loss: 0.018429  [38400/60000]\n",
            "loss: 0.000632  [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.1%, Avg loss: 0.086079 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.001141  [    0/60000]\n",
            "loss: 0.001700  [12800/60000]\n",
            "loss: 0.001301  [25600/60000]\n",
            "loss: 0.022548  [38400/60000]\n",
            "loss: 0.000777  [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.8%, Avg loss: 0.101089 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.002616  [    0/60000]\n",
            "loss: 0.002284  [12800/60000]\n",
            "loss: 0.000135  [25600/60000]\n",
            "loss: 0.000071  [38400/60000]\n",
            "loss: 0.001713  [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.8%, Avg loss: 0.099660 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.014500  [    0/60000]\n",
            "loss: 0.000843  [12800/60000]\n",
            "loss: 0.023542  [25600/60000]\n",
            "loss: 0.000070  [38400/60000]\n",
            "loss: 0.017521  [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.0%, Avg loss: 0.091173 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.047686  [    0/60000]\n",
            "loss: 0.000769  [12800/60000]\n",
            "loss: 0.000036  [25600/60000]\n",
            "loss: 0.000508  [38400/60000]\n",
            "loss: 0.025034  [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.2%, Avg loss: 0.088043 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.001960  [    0/60000]\n",
            "loss: 0.001433  [12800/60000]\n",
            "loss: 0.000153  [25600/60000]\n",
            "loss: 0.001980  [38400/60000]\n",
            "loss: 0.005715  [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.2%, Avg loss: 0.090543 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.003849  [    0/60000]\n",
            "loss: 0.002049  [12800/60000]\n",
            "loss: 0.006678  [25600/60000]\n",
            "loss: 0.011596  [38400/60000]\n",
            "loss: 0.020965  [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.0%, Avg loss: 0.088011 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.000076  [    0/60000]\n",
            "loss: 0.000302  [12800/60000]\n",
            "loss: 0.000423  [25600/60000]\n",
            "loss: 0.011947  [38400/60000]\n",
            "loss: 0.027796  [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.0%, Avg loss: 0.085792 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.003374  [    0/60000]\n",
            "loss: 0.000134  [12800/60000]\n",
            "loss: 0.000193  [25600/60000]\n",
            "loss: 0.011278  [38400/60000]\n",
            "loss: 0.006227  [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.3%, Avg loss: 0.087838 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.000562  [    0/60000]\n",
            "loss: 0.000355  [12800/60000]\n",
            "loss: 0.031419  [25600/60000]\n",
            "loss: 0.000316  [38400/60000]\n",
            "loss: 0.000043  [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.0%, Avg loss: 0.090876 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.001461  [    0/60000]\n",
            "loss: 0.018610  [12800/60000]\n",
            "loss: 0.000535  [25600/60000]\n",
            "loss: 0.000040  [38400/60000]\n",
            "loss: 0.012423  [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.2%, Avg loss: 0.086017 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.000224  [    0/60000]\n",
            "loss: 0.000268  [12800/60000]\n",
            "loss: 0.002403  [25600/60000]\n",
            "loss: 0.001159  [38400/60000]\n",
            "loss: 0.010793  [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.2%, Avg loss: 0.091636 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.000124  [    0/60000]\n",
            "loss: 0.006022  [12800/60000]\n",
            "loss: 0.002813  [25600/60000]\n",
            "loss: 0.000323  [38400/60000]\n",
            "loss: 0.007580  [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.9%, Avg loss: 0.101670 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.000629  [    0/60000]\n",
            "loss: 0.016171  [12800/60000]\n",
            "loss: 0.000845  [25600/60000]\n",
            "loss: 0.000155  [38400/60000]\n",
            "loss: 0.029603  [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.0%, Avg loss: 0.097777 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.014383  [    0/60000]\n",
            "loss: 0.004368  [12800/60000]\n",
            "loss: 0.000004  [25600/60000]\n",
            "loss: 0.000804  [38400/60000]\n",
            "loss: 0.001103  [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.1%, Avg loss: 0.092155 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.000047  [    0/60000]\n",
            "loss: 0.000080  [12800/60000]\n",
            "loss: 0.000101  [25600/60000]\n",
            "loss: 0.001276  [38400/60000]\n",
            "loss: 0.000132  [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 97.9%, Avg loss: 0.112447 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.002246  [    0/60000]\n",
            "loss: 0.000244  [12800/60000]\n",
            "loss: 0.019170  [25600/60000]\n",
            "loss: 0.036198  [38400/60000]\n",
            "loss: 0.003457  [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.2%, Avg loss: 0.085137 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.021375  [    0/60000]\n",
            "loss: 0.003318  [12800/60000]\n",
            "loss: 0.000034  [25600/60000]\n",
            "loss: 0.000232  [38400/60000]\n",
            "loss: 0.004822  [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.3%, Avg loss: 0.084300 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.000097  [    0/60000]\n",
            "loss: 0.012429  [12800/60000]\n",
            "loss: 0.001842  [25600/60000]\n",
            "loss: 0.000185  [38400/60000]\n",
            "loss: 0.000175  [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.1%, Avg loss: 0.099986 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.000038  [    0/60000]\n",
            "loss: 0.000725  [12800/60000]\n",
            "loss: 0.006344  [25600/60000]\n",
            "loss: 0.014209  [38400/60000]\n",
            "loss: 0.001610  [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.2%, Avg loss: 0.087536 \n",
            "\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "loss: 0.018631  [    0/60000]\n",
            "loss: 0.000044  [12800/60000]\n",
            "loss: 0.000075  [25600/60000]\n",
            "loss: 0.000211  [38400/60000]\n",
            "loss: 0.012598  [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.2%, Avg loss: 0.092950 \n",
            "\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "loss: 0.002592  [    0/60000]\n",
            "loss: 0.000454  [12800/60000]\n",
            "loss: 0.000246  [25600/60000]\n",
            "loss: 0.000047  [38400/60000]\n",
            "loss: 0.002656  [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.2%, Avg loss: 0.103705 \n",
            "\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "loss: 0.000798  [    0/60000]\n",
            "loss: 0.000127  [12800/60000]\n",
            "loss: 0.000003  [25600/60000]\n",
            "loss: 0.000024  [38400/60000]\n",
            "loss: 0.000051  [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.1%, Avg loss: 0.110913 \n",
            "\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "loss: 0.000020  [    0/60000]\n",
            "loss: 0.000099  [12800/60000]\n",
            "loss: 0.000069  [25600/60000]\n",
            "loss: 0.000278  [38400/60000]\n",
            "loss: 0.000523  [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.1%, Avg loss: 0.101325 \n",
            "\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "loss: 0.008245  [    0/60000]\n",
            "loss: 0.000026  [12800/60000]\n",
            "loss: 0.000064  [25600/60000]\n",
            "loss: 0.000062  [38400/60000]\n",
            "loss: 0.000794  [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.2%, Avg loss: 0.096728 \n",
            "\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "loss: 0.000151  [    0/60000]\n",
            "loss: 0.000259  [12800/60000]\n",
            "loss: 0.002923  [25600/60000]\n",
            "loss: 0.000060  [38400/60000]\n",
            "loss: 0.000120  [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.1%, Avg loss: 0.098353 \n",
            "\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "loss: 0.000469  [    0/60000]\n",
            "loss: 0.000038  [12800/60000]\n",
            "loss: 0.000028  [25600/60000]\n",
            "loss: 0.000077  [38400/60000]\n",
            "loss: 0.008633  [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.1%, Avg loss: 0.098056 \n",
            "\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "loss: 0.000075  [    0/60000]\n",
            "loss: 0.000182  [12800/60000]\n",
            "loss: 0.002208  [25600/60000]\n",
            "loss: 0.000020  [38400/60000]\n",
            "loss: 0.001832  [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.1%, Avg loss: 0.105485 \n",
            "\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "loss: 0.000556  [    0/60000]\n",
            "loss: 0.000057  [12800/60000]\n",
            "loss: 0.004198  [25600/60000]\n",
            "loss: 0.039176  [38400/60000]\n",
            "loss: 0.000513  [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.3%, Avg loss: 0.086783 \n",
            "\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "loss: 0.000049  [    0/60000]\n",
            "loss: 0.001134  [12800/60000]\n",
            "loss: 0.000125  [25600/60000]\n",
            "loss: 0.000025  [38400/60000]\n",
            "loss: 0.001976  [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.1%, Avg loss: 0.103959 \n",
            "\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "loss: 0.001570  [    0/60000]\n",
            "loss: 0.000091  [12800/60000]\n",
            "loss: 0.000284  [25600/60000]\n",
            "loss: 0.001897  [38400/60000]\n",
            "loss: 0.003024  [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.5%, Avg loss: 0.082283 \n",
            "\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "loss: 0.000340  [    0/60000]\n",
            "loss: 0.000010  [12800/60000]\n",
            "loss: 0.000014  [25600/60000]\n",
            "loss: 0.000079  [38400/60000]\n",
            "loss: 0.001143  [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.4%, Avg loss: 0.087559 \n",
            "\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "loss: 0.000034  [    0/60000]\n",
            "loss: 0.000196  [12800/60000]\n",
            "loss: 0.000067  [25600/60000]\n",
            "loss: 0.024970  [38400/60000]\n",
            "loss: 0.006956  [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.1%, Avg loss: 0.118482 \n",
            "\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "loss: 0.000504  [    0/60000]\n",
            "loss: 0.000428  [12800/60000]\n",
            "loss: 0.000339  [25600/60000]\n",
            "loss: 0.000037  [38400/60000]\n",
            "loss: 0.038506  [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.1%, Avg loss: 0.114960 \n",
            "\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "loss: 0.000362  [    0/60000]\n",
            "loss: 0.016902  [12800/60000]\n",
            "loss: 0.011320  [25600/60000]\n",
            "loss: 0.000200  [38400/60000]\n",
            "loss: 0.007161  [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.2%, Avg loss: 0.096778 \n",
            "\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "loss: 0.000130  [    0/60000]\n",
            "loss: 0.003623  [12800/60000]\n",
            "loss: 0.001589  [25600/60000]\n",
            "loss: 0.000328  [38400/60000]\n",
            "loss: 0.000006  [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.2%, Avg loss: 0.094489 \n",
            "\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "loss: 0.000048  [    0/60000]\n",
            "loss: 0.013239  [12800/60000]\n",
            "loss: 0.000424  [25600/60000]\n",
            "loss: 0.044192  [38400/60000]\n",
            "loss: 0.000410  [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.4%, Avg loss: 0.100887 \n",
            "\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "loss: 0.000209  [    0/60000]\n",
            "loss: 0.002817  [12800/60000]\n",
            "loss: 0.000019  [25600/60000]\n",
            "loss: 0.000193  [38400/60000]\n",
            "loss: 0.004626  [51200/60000]\n",
            "Test Error: \n",
            " Accuracy: 98.4%, Avg loss: 0.095871 \n",
            "\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "loss: 0.000001  [    0/60000]\n",
            "loss: 0.000027  [12800/60000]\n",
            "loss: 0.000187  [25600/60000]\n",
            "loss: 0.001443  [38400/60000]\n"
          ]
        }
      ],
      "source": [
        "epochs = 100\n",
        "model.train()\n",
        "for t in range(epochs) :\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(loaders[\"train\"], model, loss_func, optimizer)\n",
        "    test(model, loaders, loss_func)\n",
        "print(\"Done.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8zqOAPkCV1O"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}